# MATILDA Recommendation System

**M**achine-Learning **A**dvisor **T**o **I**dentify **L**ibrary-related **D**ecision **A**lternatives

A research prototype that provides AI-powered technology migration recommendations based on real-world software evolution patterns mined from GitHub projects.

## Overview

MATILDA analyzes software projects and recommends alternative technologies by:
1. Extracting technologies from user queries or Maven `pom.xml` files
2. Finding similar projects in a Neo4j knowledge graph containing migration patterns
3. Analyzing design decisions and technology migrations from those projects
4. Generating AI-powered explanations using Large Language Models (OpenAI, Gemini, Claude, Mistral)
5. Presenting recommendations through an interactive Gradio web interface

The system consists of two main components:
- **FastAPI Backend** (Port 8000): REST API for baseline and MATILDA-enhanced recommendations
- **Gradio Frontend** (Port 7860): Interactive web interface for queries and results

## Architecture

```
recommendation_system/
├── recomsystem/
│   ├── api/              # LLM API integrations (OpenAI, Google, Anthropic, Mistral)
│   ├── config/           # Configuration, prompts, LLM definitions
│   ├── connectors/       # Database connectors (Neo4j)
│   ├── handler/          # Request handlers for baseline/MATILDA endpoints
│   ├── matilda/          # Core MATILDA logic (relevance, shared utilities)
│   ├── model/            # Pydantic models for requests/responses
│   ├── processing/       # Recommendation processing, Maven parsing, LLM queries
│   ├── ui/               # Gradio web interface components
│   └── main.py           # Application entry point (FastAPI + Gradio)
├── tests/                # Unit tests
├── pyproject.toml        # Poetry dependencies
├── .env.example          # Environment variables template
└── README.md
```

## Quick Start

### Prerequisites
- Python 3.12
- Poetry
- Neo4j database (populated with technology migration data)
- API keys for LLM providers

### Installation

1. **Install dependencies**:
   ```bash
   poetry install
   ```

2. **Install Poppler** (required for PDF processing):
   ```
   # macOS
   brew install poppler
   
   # Ubuntu/Debian
   apt-get install poppler-utils
   
   # Windows: See https://pypi.org/project/pdf2image/
   ```

3. **Configure environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env and add:
   # - NEO4J_PASSWORD (required)
   # - OPENAI_API_KEY (required for OpenAI models)
   # - GCLOUD_PROJECT_ID (required for Google/Anthropic/Mistral via Vertex AI)
   ```

4. **Start Neo4j database**:
   ```bash
   docker run -d \
     --name neo4j \
     -p 7474:7474 -p 7687:7687 \
     -e NEO4J_AUTH=neo4j/your_password \
     neo4j:latest
   ```
   
   **Note**: The database must be pre-populated with technology migration data from the data crawling system.

5. **Run the application**:
   ```bash
   poetry run python -m recomsystem.main
   ```
   
   Access:
   - Web UI: http://127.0.0.1:7860
   - API Docs: http://127.0.0.1:8000/docs

## API Endpoints

### POST /chat/baseline
Get technology recommendations using LLM only (without MATILDA knowledge graph).

**Request**:
```json
{
  "message": "What is the best UI framework for Java?",
  "llm": "GEMINI_2_5_FLASH",
  "dependencies": []
}
```

### POST /chat/matilda
Get MATILDA-enhanced recommendations using knowledge graph and migration patterns.

**Request**: Same as `/chat/baseline`

**Response**: Includes filtered/unfiltered recommendations, migration patterns, and detailed insights.

### Supported LLMs
- **OpenAI**: GPT-4, GPT-3.5 (requires `OPENAI_API_KEY`)
- **Google Gemini**: Gemini Pro, Flash (requires `GCLOUD_PROJECT_ID`)
- **Anthropic Claude**: Claude 3 via Vertex AI (requires `GCLOUD_PROJECT_ID`)
- **Mistral**: Via Vertex AI (requires `GCLOUD_PROJECT_ID`)

## Data Requirements

MATILDA requires three CSV files in the `data/` directory (generated by the data crawling system):

1. **libs_to_predict_result.csv**: Mapping from Maven GA to technology names
2. **matilda-design-decisions-[timestamp].csv**: Technology migration patterns from GitHub
3. **category_tech_map(generated).csv**: Technology categorization and centrality scores

These files are generated by running the data crawling pipeline (see `../data_crawling_system/`).

## Testing

```bash
# Run all tests
poetry run pytest tests/

# Run specific test
poetry run pytest tests/recommendation_processor_test.py -v
```
