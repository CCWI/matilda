spring.main.sources=edu.hm.ccwi.matilda.dataextractor
spring.application.name=matilda-dataextractor

server.port=0

# security
spring.security.user.name=admin
spring.security.user.password=${ADMIN_PASSWORD:changeme}

# dataextractor
# Batch-Crawling should ignore existing repos - In Prod false to enable repo-updates
matilda.dataextractor.ignore.existingRepos=false
matilda.dataextractor.project.revision.maximum=10000
matilda.dataextractor.project.dependency.maximum=1000

# libsim
matilda.libsim.url=http://matilda-libsim-ki:5000

# discovery
eureka.enabled=true
eureka.client.register-with-eureka=true
eureka.client.fetchRegistry=true
eureka.client.serviceUrl.defaultZone=http://matilda-discovery:8761/eureka/

# mongoDB
spring.data.mongodb.host=mongo
spring.data.mongodb.port=27017
spring.data.mongodb.database=matilda

# jpa
spring.jpa.show-sql=false
spring.jpa.hibernate.ddl-auto=update

spring.jpa.hibernate.show-sql=false
spring.jpa.properties.hibernate.format_sql=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQL95Dialect

spring.datasource.driver-class-name=org.postgresql.Driver
spring.datasource.url = jdbc:postgresql://postgres:5432/matilda
spring.datasource.username = max
spring.datasource.password = ${DB_PASSWORD:}

# kafka
matilda.kafka.ui.response=matildaUiResponse
matilda.kafka.extractor.topic=matildaExtractorTopic
matilda.kafka.analyzer.topic=matildaAnalyzerTopic
spring.kafka.bootstrap-servers=kafka-broker:9092
#Local config ouside of docker: localhost:9092

# kafka consumer
spring.kafka.consumer.client-id=${random.int[1,9999]}
spring.kafka.consumer.group-id=dataExtractorGroup
spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

# kafka producer
spring.kafka.producer.retries=3
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
